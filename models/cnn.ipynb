{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, ReLU\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from utils.write import write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe = pd.read_csv('../data_frames/test_dataframe.csv', sep=',', names=['id']).astype(str)\n",
    "validation_dataframe = pd.read_csv('../data_frames/validation_dataframe.csv', sep=',', names=['id', 'class']).astype(\n",
    "    str)\n",
    "train_dataframe = pd.read_csv('../data_frames/train_dataframe.csv', sep=',', names=['id', 'class']).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "train_dataframe['class'].value_counts().plot(kind='bar', ax=ax[0], title='Train')\n",
    "validation_dataframe['class'].value_counts().plot(kind='bar', ax=ax[1], title='Validation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALCULATE CLASS WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.5876821814762576, 1: 3.351206434316354}\n"
     ]
    }
   ],
   "source": [
    "train = train_dataframe['class'].values\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(train), y=train)\n",
    "\n",
    "class_weights = {0: class_weights[0], 1: class_weights[1]}\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_path = os.path.join(os.getcwd(), '../data/data/')\n",
    "batch_size = 35\n",
    "image_resize = (224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DATA AUGMENTATION FUNCTION"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def contrast_stretching(image, min_output=0, max_output=255):\n",
    "    # Find the minimum and maximum pixel values in the image\n",
    "    min_input = np.min(image)\n",
    "    max_input = np.max(image)\n",
    "\n",
    "    # Check if the input image has any variation in pixel values\n",
    "    if min_input == max_input:\n",
    "        return image\n",
    "\n",
    "    # Calculate the scaling factor\n",
    "    scale_factor = (max_output - min_output) / (max_input - min_input)\n",
    "\n",
    "    # Apply contrast stretching to the image\n",
    "    stretched_image = (image - min_input) * scale_factor + min_output\n",
    "    return stretched_image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA GENERATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = ImageDataGenerator(\n",
    "    rescale=1. / 255.0,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    rotation_range=15,\n",
    "    fill_mode='nearest',\n",
    "    horizontal_flip=True,\n",
    "    preprocessing_function=contrast_stretching,\n",
    ")\n",
    "\n",
    "validation_data_gen = ImageDataGenerator(\n",
    "    rescale=1. / 255.0,\n",
    "    preprocessing_function=contrast_stretching,\n",
    ")\n",
    "\n",
    "test_data_gen = ImageDataGenerator(\n",
    "    rescale=1. / 255.0,\n",
    "    preprocessing_function=contrast_stretching,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERATE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_generator = train_data_gen.flow_from_dataframe(\n",
    "    dataframe=train_dataframe,\n",
    "    directory=data_dir_path,\n",
    "    x_col='id',\n",
    "    y_col='class',\n",
    "    target_size=image_resize,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "validation_generator = validation_data_gen.flow_from_dataframe(\n",
    "    dataframe=validation_dataframe,\n",
    "    directory=data_dir_path,\n",
    "    x_col='id',\n",
    "    y_col='class',\n",
    "    target_size=image_resize,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "test_generator = test_data_gen.flow_from_dataframe(\n",
    "    dataframe=test_dataframe,\n",
    "    directory=data_dir_path,\n",
    "    x_col='id',\n",
    "    y_col=None,\n",
    "    target_size=image_resize,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AUGMENTED DATA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    io.imshow(img)\n",
    "    io.show()\n",
    "\n",
    "\n",
    "image_batch, label_batch = next(train_generator)\n",
    "print(len(image_batch))\n",
    "for i in range(0, 5):\n",
    "    image = image_batch[i]\n",
    "    label = label_batch[i]\n",
    "    print(label)\n",
    "    imshow(image)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 SCORE METRIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALLBACKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, verbose=1, mode='auto', min_delta=1e-7,\n",
    "                               cooldown=1, min_lr=1e-7)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_score', min_delta=1e-4, patience=60, verbose=1, mode='max', baseline=None,\n",
    "                           restore_best_weights=True)\n",
    "\n",
    "checkpoint_path = \"saved_models/model_weights.{epoch:02d}-{val_loss:.2f}--{val_score:.2f}.h5\"\n",
    "checkpoint_callback = ModelCheckpoint(checkpoint_path, verbose=0)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=f\"logs/{time()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Conv2D(filters=32, kernel_size=3, padding='same',\n",
    "               input_shape=(image_resize[0], image_resize[1], 1)),\n",
    "        BatchNormalization(),\n",
    "        ReLU(),\n",
    "        Conv2D(filters=32, kernel_size=3, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        ReLU(),\n",
    "        MaxPooling2D(),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        Conv2D(filters=64, kernel_size=3, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        ReLU(),\n",
    "        Conv2D(filters=64, kernel_size=3, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        ReLU(),\n",
    "        MaxPooling2D(),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        Conv2D(filters=128, kernel_size=3, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        ReLU(),\n",
    "        Conv2D(filters=128, kernel_size=3, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        ReLU(),\n",
    "        Conv2D(filters=128, kernel_size=3, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        ReLU(),\n",
    "        MaxPooling2D(),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        Conv2D(filters=256, kernel_size=3, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        ReLU(),\n",
    "        Conv2D(filters=256, kernel_size=3, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        ReLU(),\n",
    "        Conv2D(filters=256, kernel_size=3, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        ReLU(),\n",
    "        MaxPooling2D(),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(256),\n",
    "        ReLU(),\n",
    "        BatchNormalization(),\n",
    "        Dense(256),\n",
    "        ReLU(),\n",
    "        BatchNormalization(),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = time()\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=binary_crossentropy, metrics=[score])\n",
    "\n",
    "history = model.fit(train_generator, epochs=500, batch_size=batch_size, verbose=1,\n",
    "                    validation_data=validation_generator, class_weight=class_weights,\n",
    "                    callbacks=[early_stop, tensorboard, learn_rate, checkpoint_callback])\n",
    "\n",
    "print(f\"--------------------------- {time() - start} ---------------------------\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['score'])\n",
    "plt.plot(history.history['val_score'])\n",
    "plt.title('Model Score')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CONFUSION MATRIX"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "def show(matrix, type):\n",
    "    classes = [0, 1]\n",
    "    plt.imshow(matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix \" + type)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = 'd'\n",
    "    thresh = matrix.max() / 2.\n",
    "    for i, j in itertools.product(range(matrix.shape[0]), range(matrix.shape[1])):\n",
    "        plt.text(j, i, format(matrix[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if matrix[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CONFUSION MATRIX TRAIN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "train_predicted_labels = model.predict(train_generator, verbose=1)\n",
    "train_predicted_labels = np.round(train_predicted_labels).astype(int).reshape(-1, )\n",
    "train_classes = train_generator.classes\n",
    "cm = confusion_matrix(train_classes, train_predicted_labels)\n",
    "show(cm, \"Train\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CONFUSION MATRIX VALIDATION"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_predicted_labels = model.predict(validation_generator, verbose=1)\n",
    "val_predicted_labels = np.round(val_predicted_labels).astype(int).reshape(-1, )\n",
    "val_classes = validation_generator.classes\n",
    "cm = confusion_matrix(val_classes, val_predicted_labels)\n",
    "show(cm, \"Validation\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predicted_labels = model.predict(test_generator, verbose=1)\n",
    "predicted_labels = np.round(predicted_labels).astype(int).reshape(-1, )\n",
    "\n",
    "write(predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CLASSIFICATION REPORT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predicted_labels = model.predict(validation_generator, verbose=1)\n",
    "predicted_labels = np.round(predicted_labels).astype(int).reshape(-1, )\n",
    "val_classes = validation_generator.classes\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(val_classes, predicted_labels, target_names=['0', '1']))\n",
    "print()\n",
    "\n",
    "print(f\"-----------------------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
